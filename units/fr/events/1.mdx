# Événement pour la sortie du cours

Pour accompagner la sortie du cours, nous organisons un **événement communautaire en direct le 30 novembre 2022** auquel vous êtes conviés ! Au programme, des interventions passionnantes des créateurs de Stable Diffusion, des chercheurs de Stability AI et de Meta, et bien d'autres encore !

Les interventions se concentreront sur une présentation de haut niveau des modèles de diffusion et des outils permettant de créer des applications.

**Intelligence collective et IA créative** par **David Ha**
David Ha est responsable de la stratégie chez Stability AI. Auparavant, il a travaillé comme chercheur chez Google, au sein de l'équipe Brain au Japon. Ses recherches portent sur les systèmes complexes, l'auto-organisation et les applications créatives de l'apprentissage automatique. Avant de rejoindre Google, il a travaillé chez Goldman Sachs en tant que Managing Director, où il a codirigé les activités de négociation de titres à revenu fixe au Japon. Il a obtenu une licence et une maîtrise à l'université de Toronto, ainsi qu'un doctorat à l'université de Tokyo.
Vous pouvez le trouver sur [Twitter](https://twitter.com/hardmaru) ou sur son [site personnel](https://otoro.net/ml/).
<Youtube id="00GKzGyWFEs" />

**IA pour augmenter la créativité humaine** par **Devi Parikh**  
Devi Parikh est directrice de recherche au laboratoire *Fundamental AI Research* (FAIR) de Meta et professeur associé à l'école d'informatique interactive de Georgia Tech. Elle a occupé des postes d'intervenante à l'université Cornell, à l'université du Texas à Austin, à Microsoft Research, au MIT, à l'université Carnegie Mellon et à Facebook AI Research. Elle a obtenu sa maîtrise et son doctorat du département d'ingénierie électrique et informatique de l'université Carnegie Mellon en 2007 et 2009 respectivement. Ses recherches portent sur la vision artificielle, le traitement du langage naturel, l'intelligence artificielle incarnée, la collaboration entre l'homme et l'intelligence artificielle et l'intelligence artificielle au service de la créativité.
Vous pouvez la trouver sur [Twitter](https://twitter.com/deviparikh) ou sur son [site personnel](https://faculty.cc.gatech.edu/~parikh/).
<Youtube id="bucUO6_0FGU" />

**Nourriture pour Diffusion** par **Patrick Esser**
Patrick Esser est chercheur principal chez Runway, où il dirige les efforts de recherche appliquée, notamment le modèle de base de Stable Diffusion, également connu sous le nom de *High-Resolution Image Synthesis with Latent Diffusion Models*.
Vous pouvez le trouver sur [Twitter](https://twitter.com/pess_r).
<Youtube id="g6tIUrMvOec" />

**Au-delà du texte : Donner de nouvelles capacités à Stable Diffusion** par **Justin Pinkney**
Justin est chercheur senior en apprentissage automatique chez Lambda Labs. Il travaille sur la génération et l'édition d'images, en particulier pour les applications artistiques et créatives. Il adore jouer et bidouiller des modèles pré-entraînés pour leur ajouter de nouvelles capacités, et est probablement mieux connu pour des modèles comme : Toonify, Stable Diffusion Image Variations, et Text-to-Pokemon.
Vous pouvez le trouver sur [Twitter](https://twitter.com/Buntworthy) ou sur son [site personnel](https://www.justinpinkney.com).
<Youtube id="mpMGwQa7J1w" />

**Les modèles de diffusion sont cool mais qu'arrive t'il après après l'engouement ?** par **Apolinário Passos**
Apolinário Passos est un ingénieur en apprentissage automatique chez Hugging Face et un artiste qui se concentre sur l'art génératif et les médias génératifs. Il a fondé la plateforme multimodal.art et le compte Twitter correspondant, et travaille sur l'organisation, l'agrégation et la plateformisation des modèles d'apprentissage automatique des médias génératifs open-source.
Vous pouvez le trouver sur [Twitter](https://twitter.com/multimodalart).
<Youtube id="eqOSQeQNqaw" />

**Stable Diffusion et amis : Synthèse d'images en haute résolution via des modèles génératifs en deux étapes** par **Robin Rombach**
Robin est chercheur à Stability AI. Après avoir étudié la physique à l'Université de Heidelberg de 2013 à 2020, il a commencé un doctorat en informatique dans le groupe Computer Vision à Heidelberg en 2020 sous la supervision de Björn Ommer et a déménagé à LMU Munich avec le groupe de recherche en 2021. Ses recherches portent sur les modèles génératifs d'apprentissage profond, en particulier les systèmes texte-image. Au cours de son doctorat, Robin a joué un rôle déterminant dans le développement et la publication de plusieurs projets désormais largement utilisés, tels que VQGAN et Taming Transformers, et Latent Diffusion Models. En collaboration avec Stability AI, Robin a mis à l'échelle l'approche de diffusion latente et a publié une série de modèles maintenant connus sous le nom de Stable Diffusion, qui ont été largement adaptés par la communauté.
Vous pouvez le trouver sur [Twitter](https://twitter.com/robrombach).
<Youtube id="eqOSQeQNqaw" />