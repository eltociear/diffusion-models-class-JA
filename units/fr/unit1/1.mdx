# Vue d'ensemble

<CourseFloatingBanner
    unit={1}
    classNames="absolute z-10 right-0 top-0"
/>

Dans cette unit√©, vous apprendrez les bases de fonctionnement des mod√®les de diffusion et comment cr√©er les v√¥tres √† l'aide de la biblioth√®que ü§ó *Diffusers*.

## Vue d'ensemble de cette unit√© :rocket:

Les diff√©rentes √©tapes √† suivre pour cette unit√© :

- Lisez le mat√©riel d'introduction ci-dessous ainsi que toutes les ressources suppl√©mentaires list√©es en bas de page qui vous sembleront int√©ressantes.
- Consultez le *notebook* _**Introduction √† Diffusers**_ pour mettre en pratique la th√©orie avec la biblioth√®que ü§ó *Diffusers*.
- Entra√Ænez et partagez votre propre mod√®le de diffusion en utilisant le *notebook* ou le script d'entra√Ænement associ√©.
- (Facultatif) Approfondissez avec le *notebook* _**Impl√©mentation √† partir de 0**_ des mod√®les de diffusion √† partir de z√©ro si vous souhaitez voir une impl√©mentation minimale √† partir de z√©ro et explorer les diff√©rentes d√©cisions de conception en jeu.
- (Facultatif) Regardez [cette vid√©o](https://www.youtube.com/watch?v=09o5cv6u76c) (en anglais) pour une pr√©sentation informelle du mat√©riel de cette unit√©. 

 
## Que sont les mod√®les de diffusion ?

Les mod√®les de diffusion sont un ajout relativement r√©cent √† un groupe d'algorithmes connus sous le nom de *mod√®les g√©n√©ratifs*. L'objectif de la mod√©lisation g√©n√©rative est d'apprendre √† **g√©n√©rer** des donn√©es, telles que des images ou des sons, √† partir d'un certain nombre d'exemples d'entra√Ænement. Un bon mod√®le g√©n√©ratif cr√©era un ensemble **diversifi√©** de sorties qui ressemblent aux donn√©es d'entra√Ænement sans √™tre des copies exactes. Comment les mod√®les de diffusion y parviennent-ils ? Concentrons-nous sur le cas de la g√©n√©ration d'images √† des fins d'illustration.

<div class="flex justify-center">
<img class="block dark:hidden" src="https://user-images.githubusercontent.com/10695622/174349667-04e9e485-793b-429a-affe-096e8199ad5b.png" alt="Figure tir√©e du papier DDPM de Ho et al. (2020) (https://arxiv.org/abs/2006.11239)">
<img class="hidden dark:block" src="https://user-images.githubusercontent.com/10695622/174349667-04e9e485-793b-429a-affe-096e8199ad5b.png" alt="Figure tir√©e du papier DDPM de Ho et al. (2020) (https://arxiv.org/abs/2006.11239)">
</div>
<p align="center">
    <em> Figure tir√©e du papier DDPM de Ho et al. (2020) (https://arxiv.org/abs/2006.11239). </em>
<p>


Le secret de la r√©ussite des mod√®les de diffusion r√©side dans la nature it√©rative du processus de diffusion. La g√©n√©ration commence par un bruit al√©atoire, mais celui-ci est progressivement affin√© au cours d'un certain nombre d'√©tapes jusqu'√† ce qu'une image de sortie √©merge. √Ä chaque √©tape, le mod√®le estime comment nous pourrions passer de l'entr√©e actuelle *x_t* √† une version compl√®tement d√©bruit√©e *x_0*. Cependant, comme nous n'effectuons qu'un petit changement √† chaque √©tape *t*, toute erreur dans cette estimation aux premiers stades (o√π il est extr√™mement difficile de pr√©dire le r√©sultat final) peut √™tre corrig√©e dans les mises √† jour ult√©rieures. 

Entra√Æner le mod√®le est relativement simple par rapport √† d'autres types de mod√®les g√©n√©ratifs. Nous proc√©dons de mani√®re r√©p√©t√©e
1) Nous chargeons quelques images √† partir des donn√©es d'entra√Ænement.
2) Nous ajoutons du bruit, en diff√©rentes quantit√©s. N'oubliez pas que nous voulons que le mod√®le soit capable d'estimer comment ¬´ corriger ¬ª (d√©bruiter) √† la fois des images extr√™mement bruit√©es et des images qui sont proches de la perfection.
3) Nous introduisons les versions bruit√©es des donn√©es d'entr√©e dans le mod√®le.
4) Nous √©valuons l'efficacit√© du mod√®le √† d√©bruiter ces donn√©es d'entr√©e.
5) Nous utilisons ces informations pour mettre √† jour les poids du mod√®le.

Pour g√©n√©rer de nouvelles images √† l'aide d'un mod√®le entra√Æn√©, nous commen√ßons par une entr√©e totalement al√©atoire que nous soumettons au mod√®le de mani√®re r√©p√©t√©e, en l'actualisant √† chaque fois d'une petite quantit√© bas√©e sur la pr√©diction du mod√®le. Comme nous le verrons, il existe un certain nombre de m√©thodes d'√©chantillonnage qui tentent de rationaliser ce processus afin de g√©n√©rer de bonnes images en un minimum d'√©tapes.

Nous montrerons chacune de ces √©tapes en d√©tail dans les *notebooks* de l'unit√© 1. Dans l'unit√© 2, nous verrons comment ce processus peut √™tre modifi√© pour ajouter un contr√¥le suppl√©mentaire sur les r√©sultats du mod√®le par le biais d'un conditionnement suppl√©mentaire (tel qu'une √©tiquette de classe) ou de techniques telles que le guidage. Les unit√©s 3 et 4 exploreront un mod√®le de diffusion extr√™mement puissant appel√© *Stable Diffusion*, qui peut g√©n√©rer des images √† partir de descriptions textuelles.  

## Notebooks

A ce stade, vous en savez assez pour vous lancer dans les *notebooks* de cette unit√© ! Les deux *notebooks* abordent la m√™me id√©e de mani√®re diff√©rente. 
 
| Chapitre                                    | Colab                                                                                                                                                                                               | Kaggle                                                                                                                                                                                                   | Gradient                                                                                                                                                                               | Studio Lab                                                                                                                                                                                                   |
|:--------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Introduction √† Diffusers                    | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/diffusion-models-class/blob/main/fr/unit1/_introduction_to_diffusers.ipynb)              | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/huggingface/diffusion-models-class/blob/main/fr/unit1/_introduction_to_diffusers.ipynb)              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/huggingface/diffusion-models-class/blob/main/fr/unit1/_introduction_to_diffusers.ipynb)              | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/diffusion-models-class/blob/main/fr/unit1/_introduction_to_diffusers.ipynb)              |
| Impl√©mentation √† partir de 0                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/diffusion-models-class/blob/main/fr/unit1/_diffusion_models_from_scratch.ipynb)              | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/huggingface/diffusion-models-class/blob/main/fr/unit1/_diffusion_models_from_scratch.ipynb)              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/huggingface/diffusion-models-class/blob/main/fr/unit1/_diffusion_models_from_scratch.ipynb)              | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/diffusion-models-class/blob/main/fr/unit1/_diffusion_models_from_scratch.ipynb)              |



Dans _**Introduction √† Diffusers**_, nous montrons les diff√©rentes √©tapes d√©crites ci-dessus en utilisant les blocs de la biblioth√®que ü§ó *Diffusers*. 
Vous verrez rapidement comment cr√©er, entra√Æner et √©chantillonner vos propres mod√®les de diffusion sur les donn√©es de votre choix. 
√Ä la fin du *notebook*, vous serez en mesure de lire et de modifier le script d'entra√Ænement illustratif pour entra√Æner des mod√®les de diffusion et les partager avec le monde entier ! 
Ce *notebook* introduit √©galement l'exercice principal associ√© √† cette unit√©, o√π nous tenterons collectivement de trouver de bonnes ¬´ recettes d'entra√Ænement ¬ª pour les mod√®les de diffusion √† diff√©rentes √©chelles (voir la section suivante pour plus d'informations).

Dans _**Mod√®les de diffusion √† partir de 0**_, nous montrons ces m√™mes √©tapes (ajout de bruit aux donn√©es, cr√©ation d'un mod√®le, entra√Ænement et √©chantillonnage) mais impl√©ment√©es √† partir de z√©ro dans PyTorch aussi simplement que possible. 
Nous comparons ensuite cet ¬´ exemple-jouet ¬ª avec la version de ü§ó *Diffusers*, en notant les diff√©rences entre les deux et les am√©liorations qui ont √©t√© apport√©es. 
L'objectif est de se familiariser avec les diff√©rents composants et les d√©cisions de conception qui les sous-tendent, afin de pouvoir identifier rapidement les id√©es cl√©s pour une nouvelle impl√©mentation.

## Projet

Une fois les bases assimil√©es gr√¢ce aux notebooks, essayez d'entra√Æner un ou plusieurs mod√®les de diffusion ! 
Quelques suggestions sont incluses √† la fin du *notebook* _**Introduction √† Diffusers**_. 
N'oubliez pas de partager vos r√©sultats, vos recettes d'entra√Ænement et vos d√©couvertes avec la communaut√© afin que nous puissions trouver ensemble les meilleures fa√ßons d'entra√Æner ces mod√®les.

## Ressources compl√©mentaires
Une liste non exhaustive de ressources (en anglais) √† consulter :
- [Le mod√®le de diffusion annot√©](https://huggingface.co/blog/fr/annotated-diffusion) est une pr√©sentation tr√®s approfondie du code et de la th√©orie qui sous-tend les DDPM, avec des math√©matiques et du code montrant tous les diff√©rents composants. Il liste √©galement un certain nombre d'articles pour une lecture plus approfondie.  
- La documentation d'Hugging Face sur la [G√©n√©ration d'images inconditionnelle](https://huggingface.co/docs/diffusers/training/unconditional_training) contient des exemples d'entra√Ænement de mod√®les de diffusion √† l'aide du script d'entra√Ænement officiel, y compris le code montrant comment cr√©er votre propre jeu de donn√©es.  
- La vid√©o d'AI Coffee Break sur les [mod√®les de diffusion](https://www.youtube.com/watch?v=344w5h24-h8)  
- La vid√©o de Yannic Kilcher sur les [DDPM](https://www.youtube.com/watch?v=W-O7AZNzbzQ)  
Vous avez identifi√© d'autres ressources int√©ressantes ? Faites-le nous savoir et nous les ajouterons √† cette liste.