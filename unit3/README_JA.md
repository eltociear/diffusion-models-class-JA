# ãƒ¦ãƒ‹ãƒƒãƒˆ3: Stable Diffusion

Hugging Face Diffusion ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ¼ã‚¹ã®ãƒ¦ãƒ‹ãƒƒãƒˆ3ã¸ã‚ˆã†ã“ãï¼ã“ã®ãƒ¦ãƒ‹ãƒƒãƒˆã§ã¯ã€Stable Diffusion (SD) ã¨å‘¼ã°ã‚Œã‚‹å¼·åŠ›ãª diffusion ãƒ¢ãƒ‡ãƒ«ã«å‡ºä¼šã„ã€ãã‚ŒãŒã§ãã‚‹ã“ã¨ã‚’æ¢ã‚Šã¾ã™ã€‚

## ã“ã®ãƒ¦ãƒ‹ãƒƒãƒˆã‚’é–‹å§‹ã™ã‚‹ :rocket:

ãƒ¦ãƒ‹ãƒƒãƒˆã®æ‰‹é †ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:

- æ–°ã—ã„æ•™æãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸã¨ãã«é€šçŸ¥ã‚’å—ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ã€[ã“ã®ã‚³ãƒ¼ã‚¹ã«ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—](https://huggingface.us17.list-manage.com/subscribe?u=7f57e683fa28b51bfc493d048&id=ef963b4162)ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
- ä»¥ä¸‹ã®è³‡æ–™ã«ç›®ã‚’é€šã—ã€æœ¬ãƒ¦ãƒ‹ãƒƒãƒˆã®é‡è¦ãªè€ƒãˆæ–¹ã®æ¦‚è¦ã‚’ç†è§£ã—ã¦ãã ã•ã„
- [_**Stable Diffusion Introduction**_ notebook](#hands-on-notebook) ã§ã¯ã€SD ã‚’å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ã‚±ãƒ¼ã‚¹ã‚’ã”ç´¹ä»‹ã—ã¦ã„ã¾ã™
- [**hackathon** ãƒ•ã‚©ãƒ«ãƒ€](https://github.com/huggingface/diffusion-models-class/tree/main/hackathon)ã«ã‚ã‚‹ _**Dreambooth**_ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½¿ã£ã¦ã€ã‚ãªãŸã ã‘ã® Stable Diffusion ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§å…±æœ‰ã™ã‚Œã°ã€è³å“ã‚„è³å“ã‚’ç²å¾—ã™ã‚‹ãƒãƒ£ãƒ³ã‚¹ãŒã‚ã‚Šã¾ã™
- (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) [_**Stable Diffusion Deep Dive video**_](https://www.youtube.com/watch?app=desktop&v=0_BBRNYInx8) ã¨ä»˜å±ã® [_**notebook**_](https://github.com/fastai/diffusion-nbs/blob/master/Stable%20Diffusion%20Deep%20Dive.ipynb) ã§ã€ã•ã¾ã–ã¾ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¨ãã®åŠ¹æœã«ã¤ã„ã¦ã€ã‚ˆã‚Šæ·±ãæ˜ã‚Šä¸‹ã’ã¦ã¿ã¦ãã ã•ã„ã€‚ã“ã®æ•™æã¯ã€FastAI ã®æ–°ã—ã„ã‚³ãƒ¼ã‚¹ã€Œ['Stable Diffusion from the Foundations'](https://www.fast.ai/posts/part2-2022.html)ã€ã®ãŸã‚ã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚æœ€åˆã®æ•°ãƒ¬ãƒƒã‚¹ãƒ³ã¯ã™ã§ã«å…¬é–‹ã•ã‚Œã¦ãŠã‚Šã€æ®‹ã‚Šã®ãƒ¬ãƒƒã‚¹ãƒ³ã¯ä»Šå¾Œæ•°ãƒ¶æœˆã§å…¬é–‹äºˆå®šã§ã™ã€‚ã“ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã‚’å®Œå…¨ã«ã‚¼ãƒ­ã‹ã‚‰ä½œã‚‹ã“ã¨ã«èˆˆå‘³ãŒã‚ã‚‹äººã«ã¨ã£ã¦ã¯ã€ã“ã®ã‚¯ãƒ©ã‚¹ã®ç´ æ™´ã‚‰ã—ã„è£œè¶³ã«ãªã‚‹ã¯ãšã§ã™ã€‚


:loudspeaker: [Discord](https://huggingface.co/join/discord) ã«å‚åŠ ã™ã‚‹ã®ã‚’å¿˜ã‚Œãªã„ã§ãã ã•ã„ã€‚ã“ã“ã§ã¯ã€ `#diffusion-models-class` ãƒãƒ£ãƒ³ãƒãƒ«ã§æ•™æã«ã¤ã„ã¦è­°è«–ã—ãŸã‚Šã€ä½œã£ãŸã‚‚ã®ã‚’å…±æœ‰ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

## ã¯ã˜ã‚ã«

![SD example images](sd_demo_images.jpg)<br>
_Stable Diffusion ã§ç”Ÿæˆã—ãŸç”»åƒä¾‹_

Stable Diffusion ã¯ã€å¼·åŠ›ãªãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ãæ½œåœ¨çš„æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚å¿ƒé…ã—ãªã„ã§ãã ã•ã„ã€ã“ã®è¨€è‘‰ã«ã¤ã„ã¦ã¯ã™ãã«èª¬æ˜ã—ã¾ã™ ãƒ†ã‚­ã‚¹ãƒˆã®è¨˜è¿°ã‹ã‚‰ç´ æ™´ã‚‰ã—ã„ç”»åƒã‚’ä½œæˆã™ã‚‹ãã®èƒ½åŠ›ã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã§ã‚»ãƒ³ã‚»ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å·»ãèµ·ã“ã—ã¾ã—ãŸã€‚ã“ã®ãƒ¦ãƒ‹ãƒƒãƒˆã§ã¯ã€ SD ãŒã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã™ã‚‹ã‹ã‚’æ¢ã‚Šã€ä»–ã«ã©ã®ã‚ˆã†ãªãƒˆãƒªãƒƒã‚¯ãŒã§ãã‚‹ã‹ã‚’è¦‹ã¦ã„ãã“ã¨ã«ã—ã¾ã™ã€‚

## Latent Diffusion

ç”»åƒã®ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã¨ã€ãã®ç”»åƒã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã«å¿…è¦ãªè¨ˆç®—èƒ½åŠ›ã‚‚å¤§ãããªã‚Šã¾ã™ã€‚ç‰¹ã«è‡ªå·±ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨å‘¼ã°ã‚Œã‚‹æ“ä½œã§ã¯é¡•è‘—ã§ã€å…¥åŠ›æ•°ã«å¯¾ã—ã¦äºŒæ¬¡é–¢æ•°çš„ã«æ“ä½œé‡ãŒå¢—ãˆã¦ã„ãã¾ã™ã€‚128 px ã®æ­£æ–¹å½¢ç”»åƒã¯64 px ã®æ­£æ–¹å½¢ç”»åƒã®4å€ã®ç”»ç´ æ•°ã‚’æŒã¤ãŸã‚ã€è‡ªå·±ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ã§ã¯16å€ï¼ˆã¤ã¾ã‚Š4<sup>2</sup>ï¼‰ã®ãƒ¡ãƒ¢ãƒªã¨è¨ˆç®—ãŒå¿…è¦ã§ã™ã€‚ã“ã‚Œã¯ã€é«˜è§£åƒåº¦ã®ç”»åƒã‚’ç”Ÿæˆã—ãŸã„äººã«ã¨ã£ã¦ã®å•é¡Œã«ãªã‚Šã¾ã™ï¼

![latent diffusion diagram](https://github.com/CompVis/latent-diffusion/raw/main/assets/modelfigure.png)<br>
_[Latent Diffusion è«–æ–‡](http://arxiv.org/abs/2112.10752)ã‹ã‚‰ã®å›³_

ã“ã®å•é¡Œã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã«ã€ VAEï¼ˆVariational Auto-Encoderï¼‰ ã¨å‘¼ã°ã‚Œã‚‹åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€ç”»åƒã‚’ã‚ˆã‚Šå°ã•ãªç©ºé–“æ¬¡å…ƒã«åœ§ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ååˆ†ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ã€ VAE ã¯å…¥åŠ›ç”»åƒã‚’ã‚ˆã‚Šå°ã•ãè¡¨ç¾ã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã€ã“ã®å°ã•ãª **æ½œåœ¨çš„** è¡¨ç¾ã«åŸºã¥ã„ã¦ç”»åƒã‚’å¿ å®Ÿã«å†æ§‹æˆã§ãã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚ SD ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ VAE ã¯ã€3ãƒãƒ£ãƒ³ãƒãƒ«ã®ç”»åƒã‚’å–ã‚Šè¾¼ã¿ã€å„ç©ºé–“æ¬¡å…ƒã®ç¸®å°ç‡ã‚’8ã¨ã—ãŸ4ãƒãƒ£ãƒ³ãƒãƒ«ã®æ½œåƒè¡¨ç¾ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€512 px ã®æ­£æ–¹å½¢ã®å…¥åŠ›ç”»åƒã¯ã€4 x 64 x 64ã®æ½œåƒã«åœ§ç¸®ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚

ãƒ•ãƒ«è§£åƒåº¦ã®ç”»åƒã§ã¯ãªãã€ã“ã® **æ½œåœ¨çš„ãªè¡¨ç¾** ã«æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå°ã•ãªç”»åƒã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§å¾—ã‚‰ã‚Œã‚‹å¤šãã®åˆ©ç‚¹ï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‰Šæ¸›ã€UNet ã«å¿…è¦ãªãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æ¸›å°‘ã€ç”Ÿæˆæ™‚é–“ã®çŸ­ç¸®ãªã©ï¼‰ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã€æœ€çµ‚çµæœã‚’è¡¨ç¤ºã™ã‚‹æº–å‚™ãŒã§ããŸã‚‰é«˜è§£åƒåº¦ç”»åƒã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦çµæœã‚’æˆ»ã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã®é©æ–°çš„ãªæŠ€è¡“ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨å®Ÿè¡Œã«ã‹ã‹ã‚‹ã‚³ã‚¹ãƒˆãŒåŠ‡çš„ã«å‰Šæ¸›ã•ã‚Œã¾ã™ã€‚

## ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°

ãƒ¦ãƒ‹ãƒƒãƒˆ2ã§ã¯ã€UNet ã«è¿½åŠ æƒ…å ±ã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€ç”Ÿæˆã•ã‚Œã‚‹ç”»åƒã®ç¨®é¡ã‚’ã•ã‚‰ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã“ã‚Œã‚’ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã¨å‘¼ã¶ã€‚ãƒã‚¤ã‚ºã®å¤šã„ç”»åƒã‚’ä¸ãˆã‚‰ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã‚„å®‰å®šæ‹¡æ•£ã®å ´åˆã€ç”»åƒã®ãƒ†ã‚­ã‚¹ãƒˆè¨˜è¿°ãªã©ã® **è¿½åŠ çš„ãªæ‰‹ãŒã‹ã‚Š** ã«åŸºã¥ã„ã¦ã€ãƒã‚¤ã‚ºé™¤å»ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã‚’èª²ã•ã‚Œã‚‹ã€‚æ¨è«–æ™‚ã«ã¯ã€è¦‹ãŸã„ç”»åƒã®èª¬æ˜æ–‡ã¨ã€å‡ºç™ºç‚¹ã¨ã—ã¦ã®ç´”ç²‹ãªãƒã‚¤ã‚ºã‚’å…¥åŠ›ã™ã‚‹ã“ã¨ãŒã§ãã€ãƒ¢ãƒ‡ãƒ«ã¯ãƒ©ãƒ³ãƒ€ãƒ ãªå…¥åŠ›ã‚’ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¨ä¸€è‡´ã™ã‚‹ã‚‚ã®ã«'ãƒã‚¤ã‚ºé™¤å»'ã™ã‚‹ãŸã‚ã«æœ€å–„ã‚’å°½ãã—ã¾ã™ã€‚ 

![text encoder diagram](text_encoder_noborder.png)<br>
_å…¥åŠ›ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ï¼ˆencoder_hidden_statesï¼‰ã®ã‚»ãƒƒãƒˆã«å¤‰æ›ã—ã€UNet ã«æ¡ä»¶ä»˜ã‘ã¨ã—ã¦é€ã‚Šè¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å‡¦ç†ã‚’ç¤ºã™å›³ã§ã™ã€‚_

ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•°å€¤ã§è¡¨ç¾ã—ã€ãã‚ŒãŒè¨˜è¿°ã™ã‚‹å†…å®¹ã«é–¢ã™ã‚‹é–¢é€£æƒ…å ±ã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€SD ã¯ CLIP ã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã«åŸºã¥ã„ã¦äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸå¤‰æ›ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚CLIP ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€ç”»åƒã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®æ¯”è¼ƒã«ä½¿ç”¨ã§ãã‚‹å½¢å¼ã«å‡¦ç†ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ç”»åƒã®èª¬æ˜ã‹ã‚‰æœ‰ç”¨ãªè¡¨ç¾ã‚’ä½œæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã«é©ã—ã¦ã„ã¾ã™ã€‚å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€ã¾ãšãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚Œï¼ˆå„å˜èªã‚„ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰ã«ç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹å¤§è¦æ¨¡ãªèªå½™ã«åŸºã¥ã„ã¦ï¼‰ã€æ¬¡ã« CLIP ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’é€šéã—ã¦ã€å„ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦768 æ¬¡å…ƒï¼ˆSD 1.Xã®å ´åˆï¼‰ã¾ãŸã¯1024 æ¬¡å…ƒï¼ˆSD 2.Xï¼‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯å¸¸ã«77 ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã•ã«ãªã‚‹ã‚ˆã†ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°/ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ã€æ¡ä»¶ä»˜ã‘ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹æœ€çµ‚è¡¨ç¾ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã”ã¨ã«å½¢çŠ¶ 77 x 1024 ã®ãƒ†ãƒ³ã‚½ãƒ«ã«ãªã‚Šã¾ã™ã€‚

![conditioning diagram](sd_unet_color.png)

ã§ã¯ã€å®Ÿéš›ã«ã“ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°æƒ…å ±ã‚’ UNet ã«é€ã‚Šè¾¼ã¿ã€UNet ãŒäºˆæ¸¬ã‚’è¡Œã†éš›ã«åˆ©ç”¨ã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã„ã„ã®ã§ã—ã‚‡ã†ã‹ã€‚ãã®ç­”ãˆã¯ã€ã‚¯ãƒ­ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã§ã™ã€‚UNet ã«ã¯ã‚¯ãƒ­ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒæ•£åœ¨ã—ã¦ã„ã‚‹ã€‚UNet ã®å„ç©ºé–“ä½ç½®ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ã‘ã®ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã« 'attend' ã—ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰é–¢é€£æƒ…å ±ã‚’å–ã‚Šè¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚ä¸Šã®å›³ã¯ã€ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆãŠã‚ˆã³ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ãƒ™ãƒ¼ã‚¹ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼‰ãŒã€ã•ã¾ã–ã¾ãªãƒã‚¤ãƒ³ãƒˆã§ã©ã®ã‚ˆã†ã«é€ã‚Šè¾¼ã¾ã‚Œã‚‹ã‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã”è¦§ã®ã‚ˆã†ã«ã€ã©ã®ãƒ¬ãƒ™ãƒ«ã§ã‚‚ã€UNet ã¯ã“ã®æ¡ä»¶ä»˜ã‘ã‚’åˆ©ç”¨ã™ã‚‹ååˆ†ãªæ©Ÿä¼šãŒã‚ã‚Šã¾ã™ï¼

## Classifier-free ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹

It turns out that even with all of the effort put into making the text conditioning as useful as possible, the model still tends to default to relying mostly on the noisy input image rather than the prompt when making its predictions. In a way, this makes sense - many captions are only loosely related to their associated images and so the model learns not to rely too heavily on the descriptions! However, this is undesirable when it comes time to generate new images - if the model doesn't follow the prompt then we may get images out that don't relate to our description at all.

![CFG scale demo grid](cfg_example_0_1_2_10.jpeg)<br>
_Images generated from the prompt "An oil painting of a collie in a top hat" with CFG scale 0, 1, 2 and 10 (left to right)_

To fix this, we use a trick called Classifier-Free Guidance (CGF). During training, text conditioning is sometimes kept blank, forcing the model to learn to denoise images with no text information whatsoever (unconditional generation). Then at inference time, we make two separate predictions: one with the text prompt as conditioning and one without. We can then use the difference between these two predictions to create a final combined prediction that pushes **even further** in the direction indicated by the text-conditioned prediction according to some scaling factor (the guidance scale), hopefully resulting in an image that better matches the prompt. The image above shows the outputs for a prompt at different guidance scales - as you can see, higher values result in images that better match the description.

## ãã®ä»–ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã®ç¨®é¡: Super-Resolution, InpaintingåŠã³Depth-to-Image

It is possible to create versions of Stable Diffusion that take in additional kinds of conditioning. For example, the [Depth-to-Image model](https://huggingface.co/stabilityai/stable-diffusion-2-depth) has extra input channels that take in-depth information about the image being denoised, and at inference time we can feed in the depth map of a target image (estimated using a separate model) to hopefully generate an image with a similar overall structure.

![depth to image example](https://huggingface.co/stabilityai/stable-diffusion-2-depth/resolve/main/depth2image.png)<br>
_Depth-conditioned SD is able to generate different images with the same overall structure (example from StabilityAI)_

In a similar manner, we can feed in a low-resolution image as the conditioning and have the model generate the high-resolution version ([as used by the Stable Diffusion Upscaler](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler)). Finally, we can feed in a mask showing a region of the image to be re-generated as part of the 'in-painting' task, where the non-mask regions need to stay intact while new content is generated for the masked area.

## DreamBooth ã§ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

![dreambooth diagram](https://dreambooth.github.io/DreamBooth_files/teaser_static.jpg)
_Image from the [dreambooth project page](https://dreambooth.github.io/) based on the Imagen model_

DreamBooth is a technique for fine-tuning a text-to-image model to 'teach' it a new concept, such as a specific object or style. The technique was originally developed for Google's Imagen model but was quickly adapted to [work for stable diffusion](https://huggingface.co/docs/diffusers/training/dreambooth). Results can be extremely impressive (if you've seen anyone with an AI profile picture on social media recently the odds are high it came from a dreambooth-based service) but the technique is also sensitive to the settings used, so check out our notebook and [this great investigation into the different training parameters](https://huggingface.co/blog/dreambooth) for some tips on getting it working as well as possible.

## ãƒãƒ³ã‚ºã‚ªãƒ³ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯

| ç«                                      | Colab                                                                                                                                                                                               | Kaggle                                                                                                                                                                                                   | Gradient                                                                                                                                                                               | Studio Lab                                                                                                                                                                                                   |
|:--------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Stable Diffusion Introduction                                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/diffusion-models-class/blob/main/unit3/01_stable_diffusion_introduction.ipynb)              | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/huggingface/diffusion-models-class/blob/main/unit3/01_stable_diffusion_introduction.ipynb)              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/huggingface/diffusion-models-class/blob/main/unit3/01_stable_diffusion_introduction.ipynb)              | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/diffusion-models-class/blob/main/unit3/01_stable_diffusion_introduction.ipynb)              |
| DreamBooth Hackathon Notebook                      | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/diffusion-models-class/blob/main/hackathon/dreambooth.ipynb)              | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/huggingface/diffusion-models-class/blob/main/hackathon/dreambooth.ipynb)              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/huggingface/diffusion-models-class/blob/main/hackathon/dreambooth.ipynb)              | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/diffusion-models-class/blob/main/hackathon/dreambooth.ipynb)              |
| Stable Diffusion Deep Dive                               | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fastai/diffusion-nbs/blob/master/Stable%20Diffusion%20Deep%20Dive.ipynb )              | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/fastai/diffusion-nbs/blob/master/Stable%20Diffusion%20Deep%20Dive.ipynb )              | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/fastai/diffusion-nbs/blob/master/Stable%20Diffusion%20Deep%20Dive.ipynb )              | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/fastai/diffusion-nbs/blob/master/Stable%20Diffusion%20Deep%20Dive.ipynb )              |

ã“ã®æ™‚ç‚¹ã§ã€ä»˜å±ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½¿ã„å§‹ã‚ã‚‹ã®ã«ååˆ†ãªçŸ¥è­˜ãŒã‚ã‚Šã¾ã™ã€‚ä¸Šã®ãƒªãƒ³ã‚¯ã‹ã‚‰å¥½ããªãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§é–‹ã„ã¦ãã ã•ã„ã€‚ Dreambooth ã¯ã‹ãªã‚Šã®è¨ˆç®—èƒ½åŠ›ã‚’å¿…è¦ã¨ã™ã‚‹ã®ã§ã€ Kaggle ã‚„ Google Colab ã‚’ä½¿ã†å ´åˆã¯ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¿ã‚¤ãƒ—ã‚’ 'GPU' ã«è¨­å®šã—ã¦ãŠãã¨ã‚ˆã„ã§ã—ã‚‡ã†ã€‚

'Stable Diffusion Introduction' ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€ ğŸ¤— Diffusers ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã£ãŸ stable diffusion ã®ç°¡å˜ãªç´¹ä»‹ã§ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ã£ã¦ç”»åƒã‚’ç”Ÿæˆãƒ»ä¿®æ­£ã™ã‚‹åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚

DreamBooth Hackathon Notebook ï¼ˆ[ãƒãƒƒã‚«ã‚½ãƒ³ãƒ•ã‚©ãƒ«ãƒ€](https://github.com/huggingface/diffusion-models-class/tree/main/hackathon)å†…ï¼‰ã«ã¯ã€æ–°ã—ã„ã‚¹ã‚¿ã‚¤ãƒ«ã‚„ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’ã‚«ãƒãƒ¼ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã€è‡ªåˆ†ã®ç”»åƒã§ SD ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

æœ€å¾Œã«ã€ 'Stable Diffusion Deep Dive' ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨ãƒ“ãƒ‡ã‚ªã§ã¯ã€å…¸å‹çš„ãªç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’åˆ†è§£ã—ã€å„ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å¤‰æ›´ã—ã¦ã•ã‚‰ã«å‰µé€ çš„ãªåˆ¶å¾¡ã‚’è¡Œã†ãŸã‚ã®æ–¬æ–°ãªæ–¹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚


## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ 

**DreamBooth** ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®1ã¤ã«ã¤ã„ã¦ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚å„ã‚«ãƒ†ã‚´ãƒªã§æœ€ã‚‚å„ªã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶ãŸã‚ã«ã€å¿…ãšå‡ºåŠ›ä¾‹ã‚’æ·»ä»˜ã—ã¦ãã ã•ã„ã€‚è³å“ã‚„GPUã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãªã©ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ãƒãƒƒã‚«ã‚½ãƒ³æƒ…å ±](https://github.com/huggingface/diffusion-models-class/tree/main/hackathon)ã‚’ã”è¦§ãã ã•ã„ã€‚

## è¿½åŠ è³‡æ–™

- [High-Resolution Image Synthesis with Latent Diffusion Models](http://arxiv.org/abs/2112.10752) - Stable Diffusion ã®èƒŒå¾Œã«ã‚ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç´¹ä»‹ã—ãŸè«–æ–‡

- [CLIP](https://openai.com/blog/clip/) - CLIP ã¯ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®æ¥ç¶šã‚’å­¦ç¿’ã—ã€ CLIP ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’SDã§ä½¿ç”¨ã•ã‚Œã‚‹è±Šå¯Œãªæ•°å€¤è¡¨ç¾ã«å¤‰æ›ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ã€‚æœ€è¿‘ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã® CLIP ã®äºœç¨®ï¼ˆãã®ã†ã¡ã®1ã¤ãŒ SD ãƒãƒ¼ã‚¸ãƒ§ãƒ³2ã«ä½¿ã‚ã‚Œã¦ã„ã‚‹ï¼‰ã®èƒŒæ™¯ã«ã¤ã„ã¦ã¯ã€ [OpenCLIP ã«é–¢ã™ã‚‹ã“ã®è¨˜äº‹](https://wandb.ai/johnowhitaker/openclip-benchmarking/reports/Exploring-OpenCLIP--VmlldzoyOTIzNzIz)ã‚‚å‚ç…§ã—ã¦ãã ã•ã„ã€‚

- [GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models](https://arxiv.org/abs/2112.10741) ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã¨ CFG ã‚’å®Ÿè¨¼ã—ãŸåˆæœŸã®è«–æ–‡

ã‚‚ã£ã¨ç´ æ™´ã‚‰ã—ã„ãƒªã‚½ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿã“ã®ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¾ã™ã€‚
